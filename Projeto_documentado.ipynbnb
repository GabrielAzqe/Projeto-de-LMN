# ==============================================================================
# üåç AGENTE DE VIAGENS INTELIGENTE
# Projeto demonstrativo de PLN: Orquestra√ß√£o de LLM (Gemini) e Ferramentas (SerpAPI)
# Conceito central: Gera√ß√£o Aumentada por Recupera√ß√£o (RAG - Retrieval-Augmented Generation)
# ==============================================================================

# ==============================================================================
# 1. INSTALA√á√ÉO DE DEPEND√äNCIAS
# ==============================================================================
# Instala as bibliotecas necess√°rias para o LLM (Gemini), o framework de orquestra√ß√£o
# (LangChain) e a ferramenta de busca em tempo real (SerpAPI).
!pip install -U -q google-search-results langchain-google-genai langchain langchain-community

# ==============================================================================
# 2. CONFIGURA√á√ÉO E IMPORTS
# ==============================================================================
import os
import getpass
import json
from langchain_google_genai import ChatGoogleGenerativeAI
from serpapi import GoogleSearch
from datetime import datetime, timedelta

# Verifica e solicita as chaves de API.
# NOTA: O LLM (Grandes Modelos de Linguagem) √© o motor de processamento do texto,
# enquanto a SerpAPI √© a ferramenta de busca factual, fundamental para o RAG.
if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] = getpass.getpass("Cole sua Google AI Key: ")

if "SERPAPI_API_KEY" not in os.environ:
    os.environ["SERPAPI_API_KEY"] = getpass.getpass("Cole sua SerpAPI Key: ")

GOOGLE_KEY = os.environ["GOOGLE_API_KEY"]
SERPAPI_KEY = os.environ["SERPAPI_API_KEY"]


# ==============================================================================
# 3. FUN√á√ïES AUXILIARES
# ==============================================================================

def print_estruturado(titulo, content):
    """Auxiliar para imprimir resultados da SerpAPI de forma leg√≠vel."""
    print(f"\nüü¶ {titulo}\n")
    print(json.dumps(content, indent=4, ensure_ascii=False))


def configurar_llm():
    """Configura e retorna a inst√¢ncia do LLM (Gemini)."""
    # LLMs, como o Gemini, s√£o baseados na arquitetura Transformer, otimizados para
    # gera√ß√£o de texto e racioc√≠nio contextual.
    # O 'flash' √© escolhido para velocidade.
    return ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)


# ==============================================================================
# 4. FUN√á√ïES DE PROCESSAMENTO E EXTRA√á√ÉO (LLM como Classificador/Extrator)
# ==============================================================================

def gerar_dados_viagem(origem, destino, interesses):
    """
    NLP: Extra√ß√£o de Entidades e Classifica√ß√£o de Inten√ß√£o
    Usa o LLM para extrair datas de viagem do contexto da query e dos interesses.
    Este √© um caso de uso de Classifica√ß√£o de Texto/Extra√ß√£o de Informa√ß√£o,
    onde o modelo identifica e formata entidades espec√≠ficas (datas).
    """
    llm = configurar_llm()
    prompt = f"""
    Com base no contexto de uma viagem de {origem} para {destino} com interesses em '{interesses}',
    Gere uma data de partida para a pr√≥xima semana e uma data de retorno 7 dias depois.
    O retorno deve estar no formato ISO YYYY-MM-DD.
    Responda apenas com um JSON, sem texto explicativo, contendo:
    {{
        "data_ida": "YYYY-MM-DD",
        "data_volta": "YYYY-MM-DD",
        "duracao_dias": 7,
        "mes_viagem": "Novembro"
    }}
    """
    # O LLM √© instru√≠do a gerar um formato JSON, atuando como um parser estruturado.
    response = llm.invoke(prompt).content
    try:
        # Tenta corrigir poss√≠veis formata√ß√µes incorretas de JSON geradas pelo LLM.
        response = response.strip().replace("```json", "").replace("```", "")
        return json.loads(response)
    except json.JSONDecodeError:
        print(f"Erro ao decodificar JSON gerado: {response}")
        # Em caso de erro, calcula datas padr√£o como fallback para o roteiro.
        data_ida = (datetime.now() + timedelta(days=7)).strftime("%Y-%m-%d")
        data_volta = (datetime.now() + timedelta(days=14)).strftime("%Y-%m-%d")
        return {"data_ida": data_ida, "data_volta": data_volta}


def descobrir_aeroporto(cidade):
    """
    NLP: Mapeamento de Entidades e Racioc√≠nio Contextual.
    Usa o LLM para inferir o c√≥digo IATA (aeroporto) a partir do nome da cidade.
    O LLM utiliza seu vasto conhecimento pr√©-treinado para mapear entidades.
    """
    llm = configurar_llm()
    print(f"ü§î Identificando aeroporto principal de: {cidade}...")
    prompt = f"Qual o c√≥digo IATA do principal aeroporto de {cidade}? Responda apenas com o c√≥digo IATA (ex: GRU)."
    codigo = llm.invoke(prompt).content.strip().upper().replace('"', '')
    print(f"   ‚úÖ C√≥digo encontrado: {codigo}")
    return codigo


# ==============================================================================
# 5. FUN√á√ïES DE RECUPERA√á√ÉO (R - Retrieval/SerpAPI)
# Componente de factualidade na arquitetura RAG.
# ==============================================================================

def buscar_voos_reais(origem, destino, data_ida, data_volta):
    """
    Recupera informa√ß√µes de voos reais usando o motor 'google_flights' da SerpAPI.
    Garante que os dados inseridos no prompt do LLM sejam factuais e atuais.
    """
    print(f"‚úàÔ∏è  Buscando voos ({origem} -> {destino})...")
    origem_iata = descobrir_aeroporto(origem)
    destino_iata = descobrir_aeroporto(destino)

    params = {
        "engine": "google_flights",
        "departure_id": origem_iata,
        "arrival_id": destino_iata,
        "outbound_date": data_ida,
        "return_date": data_volta,
        "currency": "BRL",
        "hl": "pt",
        "api_key": SERPAPI_KEY
    }

    results = GoogleSearch(params).get_dict()
    print_estruturado("RESULTADO SERPAPI (VOOS)", results)

    # Normaliza√ß√£o dos dados recuperados para inser√ß√£o no prompt do LLM
    voos = results.get("best_flights", []) or results.get("other_flights", [])
    if not voos:
        return "Nenhum voo encontrado."

    lista = []
    for v in voos[:3]:
        preco = v.get("price", "N/A")
        duracao = v["flights"][0].get("duration", "N/A")
        cia = v["flights"][0].get("airline", "Companhia A√©rea n√£o especificada")
        lista.append(f"Pre√ßo: R$ {preco} - Dura√ß√£o: {duracao} - Cia: {cia}")

    return "\n".join(lista)


def buscar_hoteis_reais(destino, data_ida, data_volta):
    """
    Recupera informa√ß√µes de hot√©is reais usando o motor 'google_hotels' da SerpAPI.
    """
    print(f"üè®  Buscando hot√©is em {destino}...")
    # A data de check-in √© usada como a data de chegada do voo (data_ida).
    check_in = data_ida
    # A data de check-out √© 7 dias ap√≥s o check-in.
    check_out_date = datetime.strptime(data_ida, "%Y-%m-%d") + timedelta(days=7)
    check_out = check_out_date.strftime("%Y-%m-%d")

    params = {
        "engine": "google_hotels",
        "q": destino,
        "check_in_date": check_in,
        "check_out_date": check_out,
        "currency": "BRL",
        "hl": "pt",
        "api_key": SERPAPI_KEY
    }

    results = GoogleSearch(params).get_dict()
    print_estruturado("RESULTADO SERPAPI (HOT√âIS)", results)

    # Normaliza√ß√£o dos dados recuperados
    properties = results.get("properties", [])
    if not properties:
        return "Nenhum hotel encontrado."

    lista = []
    for p in properties[:3]:
        nome = p.get("name", "Hotel n√£o especificado")
        preco = p.get("price", {}).get("total_price", "N/A")
        lista.append(f"Hotel: {nome} - Pre√ßo Total para o per√≠odo: R$ {preco}")

    return "\n".join(lista)


def pesquisar_atracoes(destino, interesses):
    """
    Recupera atra√ß√µes baseadas nos interesses do usu√°rio usando o Google Search.
    O LLM receber√° essa lista para selecionar e integrar ao roteiro.
    """
    print(f"üîç  Pesquisando atra√ß√µes em {destino}...")
    q = f"melhores atra√ß√µes {destino} {interesses}"
    params = {
        "engine": "google",
        "q": q,
        "hl": "pt",
        "api_key": SERPAPI_KEY
    }

    results = GoogleSearch(params).get_dict()
    print_estruturado("RESULTADO SERPAPI (ATRA√á√ïES)", results)

    # Normaliza√ß√£o dos dados recuperados
    snippet = results.get("related_questions", [])[0].get("text_blocks", [])[0].get("snippet", "Nenhuma atra√ß√£o encontrada.")
    
    return snippet


def buscar_cambio(destino):
    """
    Recupera informa√ß√µes de c√¢mbio atual para o pa√≠s de destino.
    Essencial para o c√°lculo de custos aproximados no roteiro final.
    """
    print(f"üí±  Consultando c√¢mbio para {destino}...")
    q = f"Quanto vale R$1 no {destino}"

    params = {
        "engine": "google",
        "q": q,
        "hl": "pt",
        "api_key": SERPAPI_KEY
    }

    results = GoogleSearch(params).get_dict()
    print_estruturado("RESULTADO SERPAPI (C√ÇMBIO)", results)

    # Normaliza√ß√£o dos dados recuperados
    fs = results.get("knowledge_graph", {}).get("converter", {}).get("formatted", [])
    if fs:
        # Seleciona o primeiro snippet que mostra a convers√£o
        return f"1 BRL √© aproximadamente {fs[1].get('hoje_√†s_16_00')}"
    
    return "C√¢mbio n√£o encontrado."


def pesquisar_historia(destino):
    """
    Recupera contexto hist√≥rico sobre o destino.
    Este √© um recurso de informa√ß√£o que o LLM usar√° para enriquecer o roteiro
    com explica√ß√µes culturais (um requisito do prompt final).
    """
    print(f"üìö  Buscando contexto hist√≥rico de {destino}...")
    q = f"Hist√≥ria do {destino}"
    params = {
        "engine": "google",
        "q": q,
        "hl": "pt",
        "api_key": SERPAPI_KEY
    }
    
    results = GoogleSearch(params).get_dict()
    print_estruturado("RESULTADO SERPAPI (HIST√ìRIA)", results)

    # Normaliza√ß√£o dos dados recuperados
    snippet = results.get("knowledge_graph", {}).get("description", "Hist√≥ria n√£o encontrada.")
    if snippet == "Hist√≥ria n√£o encontrada.":
        snippet = results.get("organic_results", [])[0].get("snippet", "Hist√≥ria n√£o encontrada.")

    return snippet


# ==============================================================================
# 6. FUN√á√ÉO DE ORQUESTRA√á√ÉO E S√çNTESE (G - Generation/LLM)
# ==============================================================================

def agente_de_viagens(origem_usuario, destino_usuario, interesses):
    """
    A fun√ß√£o principal que orquestra todo o pipeline RAG.

    1. Processamento Inicial (LLM): Extrai datas.
    2. Recupera√ß√£o (SerpAPI): Busca voos, hot√©is, atra√ß√µes, c√¢mbio e hist√≥ria.
    3. Gera√ß√£o (LLM): Monta um prompt rico em contexto (In-Context Learning)
       com todos os dados recuperados para gerar a resposta final (roteiro).
    """

    # 1. EXTRA√á√ÉO DE DADOS INICIAIS (LLM)
    # Usa o LLM para determinar as datas de viagem.
    dados_viagem = gerar_dados_viagem(origem_usuario, destino_usuario, interesses)
    data_ida = dados_viagem.get("data_ida")
    data_volta = dados_viagem.get("data_volta")

    print("\n" + "="*80)
    print(f"‚úàÔ∏è  INICIANDO PLANEJAMENTO: {origem_usuario} -> {destino_usuario}")
    print(f"üìÖ DATAS PLANEJADAS: {data_ida} a {data_volta}")
    print("="*80 + "\n")

    # 2. FASE DE RECUPERA√á√ÉO (R - Retrieval)
    # Coleta dados externos em tempo real.
    voos = buscar_voos_reais(origem_usuario, destino_usuario, data_ida, data_volta)
    hoteis = buscar_hoteis_reais(destino_usuario, data_ida, data_volta)
    atracoes = pesquisar_atracoes(destino_usuario, interesses)
    cambio = buscar_cambio(destino_usuario)
    historia = pesquisar_historia(destino_usuario)

    # 3. FASE DE GERA√á√ÉO (G - Generation)
    # Configura o LLM com maior criatividade (temperature=0.5) para a s√≠ntese.
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5)

    # Montagem do Prompt Estruturado (In-Context Learning / RAG)
    # Todos os dados factuais recuperados (voos, hot√©is, c√¢mbio etc.) s√£o injetados
    # no prompt, "aumentando" o LLM para que ele n√£o precise adivinhar ou "alucinar"
    # sobre informa√ß√µes reais. Este √© o princ√≠pio fundamental do RAG.
    # A estrutura do prompt (system prompt) guia o modelo a gerar o roteiro
    # com os elementos necess√°rios (custos, justificativa, explica√ß√£o cultural).
    prompt = f"""
    Gere um roteiro extremamente detalhado para uma viagem de {origem_usuario} para {destino_usuario}.

    DADOS REAIS:
    ‚úàÔ∏è Voos:
    {voos}

    üè® Hot√©is:
    {hoteis}

    üé° Atra√ß√µes:
    {atracoes}

    üí± C√¢mbio:
    {cambio}

    üìö Hist√≥ria:
    {historia}

    DATAS:
    - Ida: {data_ida}
    - Volta: {data_volta}

    Interesses: {interesses}

    Monte:
    - Roteiro dia a dia baseado nos dados reais e interesses.
    - Explica√ß√µes culturais e hist√≥ricas sobre o destino no corpo do roteiro.
    - Custos aproximados (A√©reo, Hospedagem, Transporte Interno, Alimenta√ß√£o/Atra√ß√µes).
    - Justificativa detalhada da escolha do roteiro e como ele atende aos interesses.
    """

    # Invoca o LLM para realizar a s√≠ntese e a gera√ß√£o de texto final.
    return llm.invoke(prompt).content


# ==============================================================================
# 7. EXECU√á√ÉO DO AGENTE
# ==============================================================================
# Define os par√¢metros de entrada do usu√°rio.
origem_usuario = "S√£o Paulo"
destino_usuario = "Jap√£o"
interesses = "Cultura (templos, santu√°rios, hist√≥ria), Gastronomia (sushi, ramen, culin√°ria local), Natureza (folhas de outono, jardins, paisagens), Modernidade (tecnologia, arranha-c√©us, vida urbana), Compras (eletr√¥nicos, moda, souvenirs), Bem-estar (experi√™ncia em onsens)"

# Chamada principal
roteiro_final = agente_de_viagens(origem_usuario, destino_usuario, interesses)

# Imprime o resultado
print("\n" + "="*80)
print("‚úÖ ROTEIRO DE VIAGEM FINALIZADO PELO AGENTE GEMINI")
print("="*80)
print(roteiro_final)
